---
title: "Section 3"
format: html
---

## Using metrics responsibly in research assessment

In this this section you will explore:

-   how to use metrics responsibly in research assessment
-   an example

### Assessing Research Responsibly Using Metrics

When you are assessing research using metrics you should define a clear question that you are trying to answer, where the answer has value to your overall assessment. Defining your question clearly will help you design the assessment process and understand if research metrics will support that process.

When you have your question or task, you should break down into the following questions:

-   What do I want to understand?​
-   Will quantitative data help me reach this understanding? 
-   Can I access relevant data?
-   How will I use the data?​
-   When is it required by? 
-   What are the limitations of my data?

**What do I want to understand?​**

First of all you need to think carefully about what it is you are trying to understand, what is the question you are trying to answer, then which information might help you to do that and where in an assessment process it would be most useful to request that from applicants. You can ask people to provide this information in their application, and if you decide undertaking your own analysis involving research metrics might be useful you can identify sources of data that could be helpful.

**Will quantitative data help me reach this understanding?​**

In most research assessment processes the question you are trying to answer is usually complex - Will this candidate bring expertise in an area we don't have expertise in? Do they complement the work already ongoing in our department and will they be able to collaborate with out exisiting staff?  Has this award nominee delivered research that has changed the research field?

Research metrics could support your understanding of part of these questions, but its likely this data will need to be supported by your own assessment or the rigour or significance or approach of a candidates research outputs.

**Can I access relevant data?​**

The University has access to a number of databases you can use to access data and prepare an analysis. You may be asked to use a particular source to obtain your metrics, this might be so the requestor can ensure that the metrics they are collecting are as comparable as possible. Sometimes you might need to use a particular source because of the specific data available from that source or because of the functions that the source provides.

**How will I use the data?​**

Whether you are carrying out the analysis yourself or are you providing data for someone else to analyse you should keep a record of what you do to the data and how you obtained it, so that anyone reading your results can replicate what you have done. 

**When is it required by? ​**

The online sources you will use to find your initial data continuously update. It therefore might be appropriate to wait until nearer your deadline as further citations may be accrued. It's important to be clear and transparent about the sources you use, so always say both when and where you got your data from.

**What are the limitations of my data?**

All data have limitations, you need to think about what might be missing or whether anything has been included which perhaps shouldn’t have been.

What, if any, assumptions have you made about your data to be able to proceed with your analysis? Be clear about the limitations of your data when you record how you have used it.

### **Example**

So, how might we go about responsibly answering the question in papers in the same discipline or by the same author? Let us take this question.

*Why did paper x do so much better than paper y?​*

To begin with, we need to decide how we are quantifying ‘better’.

Once this definition is decided you can source metrics and information to do a like-for-like comparison.

You will need to be conscious of:

-   Publication date i.e. is one paper newer?
-   Open access status – can one paper be accessed by a wider potential audience?
-   Journal – if you unable to explain a difference in metrics between two outputs using the information you have, you may want to look at the publication. For example, it may be that one paper was published in a society journal, while the other was published in a multidisciplinary journal, explaining a difference in attention.

Let’s work it through with some hypothetical data.

*A.N.Other (2021) Sample paper titled X, Journal of Things,*

-   *Citation count: 25*

*A.N.Other (2023) Sample paper titled Y, Journal of Stuff,*

-   *Citation count:10*

**First - what do we mean by better?**

***better = cited more***

This is a very simple assessment and looking at the data we can determine that *Sample paper titled X* has performed better, this will be because the paper is published in 2021, 2 years before *Sample paper titled Y*, so citations have had more time to accumulate.

**However**

***better=more impact***

If we are looking at impact we cannot tell the impact of a paper from citation count alone, so we can look for more data. The original data doesn't tell us where the citation count comes from.

As I don’t know the source I will go to a database like Scopus and look at each paper to find more data. There I find the citation count, the Field Weighted Citation Impact and Plum X metrics.

-   Field Weighted Citation Impact is a normalised metric that allows us to compare papers of different ages and disciplines - 1 is considered normal or average.
-   Plum X metrics are an example of an altmetrics. These look at social media engagement, such as likes and shares, and engagement in platforms like Mendeley.

*A.N.Other (2021) Sample paper titled X, Journal of Things,*

-   Citation count: 26
-   Field Weighted Citation Impact: 1.57
-   Plum X - Captures: 10

*A.N.Other (2023) Sample paper titled Y, Journal of Stuff,*

-   Citation count: 12
-   Field Weighted Citation Impact: 1.52
-   Plum X - Captures: 9

This tells me that although *Sample paper titled X* has over double the amount of citations, the two papers have very similar Field Weighted Citation Impacts and captures so actually both papers have about the same amount of impact so *Sample paper titled X* isn’t doing much better than *Sample paper titled Y* at all.

As you can see from this example, citation numbers don’t always give you the full picture. You need to consider other factors, such as age, discipline and journal reach too. The question you ask will determine the answer you get. So, take your time and don't make snap decisions.

### **What’s next?**

Complete further sections

-   Section 3 - Using metrics in personal applications and evaluations
-   Section 4 - Assessing people using metrics

Read the [University responsible metrics policy](https://www.southampton.ac.uk/about/governance/regulations-policies/policies/responsible-research-metrics){target="_blank"}

Visit our [Libguide on Metrics](https://library.soton.ac.uk/bibliometrics){target="_blank"}

Specific question? Contact us at eprints\@soton.ac.uk

Further Resources external to the University:

-   Deakin Library Metrics Toolkit: [https://deakin.libguides.com/research-metrics/about](https://deakin.libguides.com/research-metrics/about){target="_blank"}
-   What are Responsible Metrics by University of Exeter (4 minute Youtube video): [https://www.youtube.com/watch?v=kTYb623Slg4](https://www.youtube.com/watch?v=kTYb623Slg4){target="_blank"}
