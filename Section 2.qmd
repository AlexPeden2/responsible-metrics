---
title: "Section 2"
format: html
---

## Responsible use of research metrics: Overview

In this section you will explore:

-   what are research metrics?
-   the principles of responsible use of research metrics
-   guidelines for the responsible use of research metrics

### **What are research metrics?**

Research metrics are usually quantitative data that describe an aspect of a research output at a particular time. A research output is anything which disseminates research; a journal article, a book, an exhibition, dataset or software. There are many different metrics each attempting to describe a different aspect of research. Metrics can look at one indiviudal research output, at all the outputs from a single researcher, or at the entire output of a department or University. Other metrics describe features of a publication venue, such as a journal. The majority of metrics primarily focus on research journal articles but there are metrics available for other research output types.

When engaging with research metrics its important to focus on the question you are trying to answer, or the information you are trying to convey, so you can decide if using metrics will be useful or not.

### **Principles for responsible use of metrics**

As research disciplines, research practices, research outputs and the information that needs to be conveyed are infinitely variable, there isn't one approach to engaging with metrics that can be applied universally. In all research assessment the University expects that a transparent set of both qualitative and quantitative information is used to support and inform expert human academic judgement. You will need to consider what is appropriate for the assessment you are making, and follow these principles[:]{.underline} Be Transparent, Communicate your Evaluation Methods, Ensure Suitability and Contextualise.

#### **Be Transparent** 

Provide clear information on how any quantitative data will be used in decision making, how that data will be validated or checked by those being assessed, and how the data will be supported by qualitative informtion.
Transparency in the use of research metrics means having an explanation in clear, simple language to ensure end-users understand the data used, its reliability and its limitations. 

If you decide to use metrics
-   What metrics will be used? Can you apply these across your whole analysis/candidate pool? (if not you shouldn't use these metrics)
-   Where did the data come from (sources)? 
-   When was the data extracted? – any metric represents a data point in time, citations will continue to accumulate after the metric is extracted so the date of extraction needs to be consistent
-   How will the metrics be supported by qualitative information?

#### **Communicate your Evaluation Method** 

Those leading assessment processes must ensure that the evaluation process, including any additional information to be used not provided by the candidate, is clearly communicated in advance to those being assessed.  Any quantitative indicator that will be used from either internal or external sources should be communicated, accessible, validatable and open to scrutiny.

#### **Suitability** 

When assessing a person, research metrics should not be used as the sole source of information. Metrics should only be used when necessary and should be used in conjunction with qualitative information (e.g. expert testimony or a narrative description of the significance of a research output) rather than in isolation. Use a basket of metrics rather than focusing on one data type.

Be aware that individuals are unlikely to be directly comparable due to their career path or circumstances. e.g. length of career, career breaks, part-time working, personal circumstances
-   E.g. you should not compare an early career researcher with a researcher who has 20 years of experience unless you have restricted the comparison to a suitable time frame. 

You should avoid using metrics to make comparisons across diverse groups of individuals
-   i.e. don't use one metric to compare across different research disciplines, if you are comparing across similar sub-disciplines use a normalised metric (e.g. field weighted citation impact)

Each metric has a specific use, make sure you understand what the metric is telling you before using it
-   For example, you should not use a metric that describes an aspect of a whole journal catalog (e.g. Impact Factor) to infer the quality of an individual output or one person’s contribution to an output.

#### **Contextualise** 

Research metrics should be appropriately normalised using an established method (e.g. field-weighted citation impact) or presented with suitable context (e.g. research income range by discapline or sub-discapline).

Those being assessed should have the opportunity to provide context on their own track record to communicate their career path, career breaks, work pattern or any other relvant factors.

### **Guidelines around metrics**

A number of guidelines have been published which look to shape our approach to responsible metrics.  The University has its own [responsible metrics policy](https://www.southampton.ac.uk/about/governance/regulations-policies/policies/responsible-research-metrics){target="_blank"} which is based on the principles of DORA and the Leiden Manifesto (<https://doi.org/10.1038/520429a>). Below are summaries of three key international initiatives, each of which advise on a different aspect: 

[**DORA (the Declaration of Research Assessment)**](https://sfdora.org/read/){target="_blank"} 

DORA is a set of principles that were published in 2012. They are designed to ensure that the quality and impact of scientific outputs is “measured accurately and evaluated wisely”.

DORA focuses particularly on the use of journal-based metrics. Its key tenet is to “do not use journal-based metrics, such as Journal Impact Factors (JIFs), as surrogate measures of the quality of individual research articles, to assess an individual scientist’s contributions, or in hiring, promotion, or funding decisions”. 

DORA also supports the idea that research should be assessed on its own merits and not influenced by the reputation of the journal in which it has been published. 

[**CoARA (Coalition of Advancing Research Assessment)**](https://coara.eu/app/uploads/2022/09/2022_07_19_rra_agreement_final.pdf){target="_blank"} 

The CoARA initiative was launched in January 2022 and builds on DORA and other initiatives. Its core principle is "that in the assessment of research, researchers and research organisations needs to recognise that diverse outputs, practices and activities contribute to the quality and impact of research. This requires basing assessment primarily on qualitative judgement for which peer review is central, supported by the responsible use of quantitative indicators" (metrics). 

The University of Edinburgh is a signatory of, and committed to, both DORA and CoARA.

[**Barcelona Declaration on Open Research Information**](https://barcelona-declaration.org/){target="_blank"} 

Launched in April 2024, the Barcelona Declaration has the backing of research and funding organisations who have endorsed its commitment to “make openness the default for the research information we use and produce”. 

One of its central recommendations is that we should move away from the use of closed and commercial data sources and work towards services and systems that support and enable research information which is open. These open tools should then give access to metrics that have greater transparency and reproducibility. 

### **Where might you see metrics used?**

Metrics are used in a wide range of activities such as:

-   research assessment;
-   grant applications;
-   recruitment;
-   promotion;
-   league tables, such as QS.

Thank you for taking the time to complete this section of the course.

### **What’s next?**

Complete further sections

-   Section 2 - Using metrics in research assessment.
-   Section 3 - Using metrics in personal applications and evaluations.
-   Section 4 - Assessing people using metrics.

Read the [University statement on responsible use of research metrics](https://www.ed.ac.uk/sites/default/files/2025-05/Responsible%20Research%20Metrics%20Statement%20May%202025.pdf){target="_blank"}

Visit our [Responsible Research Assessment & Use of Metrics](https://www.ed.ac.uk/research-cultures/home/responsible-research-assessment){target="_blank"} webpage

Visit our [Responsible Research Assessment & Use of Metrics](https://uoe.sharepoint.com/sites/Research_Cultures/SitePages/Responsible-Research-Assessment-&-Use-of-Metrics.aspx?csf=1&web=1&e=gpkXsz){target="_blank"} SharePoint site

Specific question? Contact us at research.cultures@ed.ac.uk

Further Resources:

-   Deakin Library Metrics Toolkit: [https://deakin.libguides.com/research-metrics/about](https://deakin.libguides.com/research-metrics/about){target="_blank"}.
-   What are Responsible Metrics by University of Exeter (4 minute Youtube video): [https://www.youtube.com/watch?v=kTYb623Slg4](https://www.youtube.com/watch?v=kTYb623Slg4){target="_blank"}.
