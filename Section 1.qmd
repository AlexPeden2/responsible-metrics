---
title: "Section 1"
format: html
---

## Responsible research assessment overview

In this first section you will explore:

-   what is research assessment?
-   why is responsible research assessment important?

### **What is research assessment?**

Research assessment is any process where you are making a judgement on the quality, significance or impact of research conducted by an individual or groups of individuals, or institution.  This could be during recruitment, annual review, promotion or redundancy processes, while reviewing proposals for funders, or during internal REF preparations or REF panels.

### **Why is responsible research assessment important?**

Research metrics, or bibliometrics, represent the quantification of publications and their characteristics.  They are a prominent feature of our research eco-system including in research assessment processes.  

When used appropriately metrics can provide valuable insights into aspects of research output. Unfortunately, research metrics are often used uncritically which can cause problems for researchers and research.

Many research metrics have become a shorthand for research quality, but they aren't based on the quality of the actual research itself.  They are a feature of who funded the research, or where it was published, or how many other people are researching a topic.  It isn't always clear how these metrics have been calculated or what each metric actually represents to most people.

Relying on research metrics to make decisions about individuals and their research isn't fair to the individual, or the work undertaken to produce the research, and can cause us to overlook important or impactful work.  There is evidence that inappropriate use of metrics has influenced our research cultures negatively.

Making sure peer-review is fore-most in our assessment of research and researchers is a route to undertaking responsible research assessment and improving our research cultures.

## Responsible use of research metrics overview

In this section you will explore:

-   what are research metrics?
-   the principles of responsible use of research metrics
-   guidelines for the responsible use of research metrics

### **What are research metrics?**

Metrics are a quantitative snapshot of how research outputs perform. A research output is anything which disseminates research; for instance a journal article, a book, an exhibition or software. Metrics can look at one research output, at the outputs from a single researcher, or at the entire output of a department or University. Other metrics indicate the relevance and quality of a venue, such as a journal, but these are not appropriate indicators to use as a proxy to assess an individual or their output. The majority of metrics primarily focus on journal articles but metrics may be available for other research output types.

There are many different types of metrics and they each have a prescribed purpose.

When using metrics it is important to have a question you are trying to answer so you can decide which metrics to use.

Using the wrong metric can have real world implications, from making false claims to causing reputational harm, which could impact future career ambitions or cause institutional damage.

### **Principles of responsible use of metrics**

As research disciplines and outputs are so varied there is no set step-by-step guide to carrying out an analysis. Instead, there are a set of principles that should be followed[:]{.underline} Transparency, Appropriateness, Equality, Reproducible, and Continual Reassessment.

#### **Transparency** 

Transparency in metrics means having an explanation in clear, simple language to ensure end-users understand the data used, its reliability and its limitations. 

Essentially what, where and when: 

-   What metrics were used? 
-   Where did the data come from (sources)? 
-   When was the assessment made? – The assessment is only a snapshot in time; data sources are updated as indicators mature. 

#### **Equality** 

The use of metrics should be fair.  You should only compare like-for-like i.e. make comparisons within a single discipline, a limited time period, or using a normalised metric.

Consistency is important. If you can't apply the same method across your analysis you should not use that method. 

Be aware that individuals may not be directly comparable due to length of service or time out of work, such as for maternity leave.

-   E.g. you should not compare an early career researcher with a researcher who has 20 years of experience unless you have restricted the comparison to a suitable time frame. 

#### **Appropriateness** 

All metrics should be tailored to the focus of the analysis. Use metrics for their intended purpose only.

-   For example, you must not use a journal metric to infer the quality of an individual output or a person’s contribution to research.

Metrics should only be used when necessary and should be used in conjunction with expert testimony rather than in isolation. 

When assessing a person, metrics must not be used as the sole source of information. This is especially true for employment status, but also for personal reputation in a formal or informal context. 

-   For example, a highly cited paper might be highly cited because everyone disagrees with it

It is recommended that you use more than one metric to verify results. 

#### **Reproducible** 

Anyone should be able to reproduce your results by using the explanation you have provided.

#### **Continually reassess** 

Continually assess commonly used metrics, especially concerning appropriateness and equality. If a metric is no longer fit for purpose, it should not be used. 

### **Guidelines around metrics**

A number of guidelines have been published which look to shape our approach to responsible metrics.  The University has its own [responsible metrics policy](https://www.southampton.ac.uk/about/governance/regulations-policies/policies/responsible-research-metrics){target="_blank"} which is based on the principles of DORA and the Leiden Manifesto (<https://doi.org/10.1038/520429a>). Below are summaries of three key international initiatives, each of which advise on a different aspect: 

[**DORA (the Declaration of Research Assessment)**](https://sfdora.org/read/){target="_blank"} 

DORA is a set of principles that were published in 2012. They are designed to ensure that the quality and impact of scientific outputs is “measured accurately and evaluated wisely”.

DORA focuses particularly on the use of journal-based metrics. Its key tenet is to “do not use journal-based metrics, such as Journal Impact Factors (JIFs), as surrogate measures of the quality of individual research articles, to assess an individual scientist’s contributions, or in hiring, promotion, or funding decisions”. 

DORA also supports the idea that research should be assessed on its own merits and not influenced by the reputation of the journal in which it has been published. 

[**CoARA (Coalition of Advancing Research Assessment)**](https://coara.eu/app/uploads/2022/09/2022_07_19_rra_agreement_final.pdf){target="_blank"} 

The CoARA initiative was launched in January 2022 and builds on DORA and other initiatives. Its core principle is "that in the assessment of research, researchers and research organisations needs to recognise that diverse outputs, practices and activities contribute to the quality and impact of research. This requires basing assessment primarily on qualitative judgement for which peer review is central, supported by the responsible use of quantitative indicators" (metrics). 

The University of Edinburgh is a signatory of, and committed to, both DORA and CoARA.

[**Barcelona Declaration on Open Research Information**](https://barcelona-declaration.org/){target="_blank"} 

Launched in April 2024, the Barcelona Declaration has the backing of research and funding organisations who have endorsed its commitment to “make openness the default for the research information we use and produce”. 

One of its central recommendations is that we should move away from the use of closed and commercial data sources and work towards services and systems that support and enable research information which is open. These open tools should then give access to metrics that have greater transparency and reproducibility. 

### **Where might you see metrics used?**

Metrics are used in a wide range of activities such as:

-   research assessment;
-   grant applications;
-   recruitment;
-   promotion;
-   league tables, such as QS.

Thank you for taking the time to complete this section of the course.

### **What’s next?**

Complete further sections

-   Section 2 - Using metrics in research assessment.
-   Section 3 - Using metrics in personal applications and evaluations.
-   Section 4 - Assessing people using metrics.

Read the [University statement on responsible use of research metrics](https://www.ed.ac.uk/sites/default/files/2025-05/Responsible%20Research%20Metrics%20Statement%20May%202025.pdf){target="_blank"}

Visit our [Responsible Research Assessment & Use of Metrics](https://www.ed.ac.uk/research-cultures/home/responsible-research-assessment){target="_blank"} webpage

Visit our [Responsible Research Assessment & Use of Metrics](https://uoe.sharepoint.com/sites/Research_Cultures/SitePages/Responsible-Research-Assessment-&-Use-of-Metrics.aspx?csf=1&web=1&e=gpkXsz){target="_blank"} SharePoint site

Specific question? Contact us at research.cultures@ed.ac.uk

Further Resources:

-   Deakin Library Metrics Toolkit: [https://deakin.libguides.com/research-metrics/about](https://deakin.libguides.com/research-metrics/about){target="_blank"}.
-   What are Responsible Metrics by University of Exeter (4 minute Youtube video): [https://www.youtube.com/watch?v=kTYb623Slg4](https://www.youtube.com/watch?v=kTYb623Slg4){target="_blank"}.
